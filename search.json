[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hushh Labs\nHushh Labs is a research and development lab focused on exploring the potential in the intersection of AI and privacy. We are a team of engineers, scientists, and entrepreneurs who are passionate about creating a future where privacy is respected and AI is used to empower individuals.\nOur mission is to create products and services that enable individuals to take control of their data and use it to their advantage. We believe that privacy is a fundamental right and that AI can be used to protect it.\nWe are currently working on a number of projects that explore the potential of AI and privacy. Our goal is to create products and services that make it easier for individuals to protect their data and use it to their advantage.\nWe are always looking for talented individuals to join our team. If you are interested in learning more about our work or joining our team, please reach out to us. We look forward to hearing from you!\ninfo@hush1one.com\n\n\n\nhushh labs"
  },
  {
    "objectID": "posts/pycon_trip_report.html",
    "href": "posts/pycon_trip_report.html",
    "title": "Pycon India 2023 Trip Report",
    "section": "",
    "text": "This year‚Äôs python conference was held at a university from 29th September to 2nd October in Hyderabad with around 1000 attendees flocking to the scene across a span of four days. The conference‚Äôs theme was mainly focused towards Generative AI relate topics and the open-source network.\nIn this blog, I will distill the most important takeaways from the conference ‚Äî latest developments, emerging fields and industries, and cool resources."
  },
  {
    "objectID": "posts/pycon_trip_report.html#key-highlights",
    "href": "posts/pycon_trip_report.html#key-highlights",
    "title": "Pycon India 2023 Trip Report",
    "section": "Key highlights",
    "text": "Key highlights\nKeynotes, talks, and workshops\nThe keynote speakers for the conference were Jessica Greene, Marcelo Trylesinski, Rushabh Mehta, Cheuk Ting Ho, and Shailesh Kumar. The keynotes were mostly about getting involved with open-source projects, transitioning into tech, and web frameworks.\n\nOpen-source and getting into tech\nJessica Greene‚Äôs keynote highlighted her journey of getting into the tech industry and the pivotal role the open-source community played in keeping her motivated throughout her transition. In addition to this transition (from a very different educational background), she highlighted the extra challenges she faced solely because she was a woman ‚Äî lack of representation, biased narratives, and a heightened feeling of the imposter syndrome.\nHer talk was very inspiring and provided constructive ways to overcoming these challenges ‚Äî joining a (preferably women-led) tech community. Jessica, personally, found her ground with the PyLadies Berlin community and recently joined the Python Software Foundation to help support the global community. If you are a woman in tech or aspiring to be one, I highly recommend these resources.\nOn a similar note, Cheuk Ting Ho‚Äôs talk focused on how one can get started with contributing to open-source libraries, the benefits, as well as overcoming some of the challenges one might face. She is also a part of the Python Software Foundation and advocates heavily for diversity among the board members to accurately represent the larger Python global community.\nTL;DR: Benefits of open-source community, PyLadies for women getting into tech, contribution benefits, open-source security (digital signing), raising issues and solving bugs.\n\n\nAll about frameworks\nMarcelo Trylesinski gave an insightful keynote about the FastAPI framework and its benefits when compared to other frameworks (Flask, Django).\nFastAPI is the way to go if your focus is to get started quickly and handle high volume requests (has async support). FastAPI has amazing integration with popular libraries for DB access and support for handling authentication. If you are currently working with Flask based applications, it would be a good idea to shift to FastAPI for faster response times (ASGI server capabilities).\nThe other cool framework for you to check out is Frappe. It‚Äôs a low-code framework customized for developing business applications. It is an integrated framework which makes it very easy to connect with payment gateways, SMS providers, cloud services, and other popular third-party tools. Rushabh Mehta (founder and CEO of Frappe), in his keynote gave a comprehensive list of applications (ERP based) that could be made with Frappe. He has created ERPNext, a free and open-source cloud ERP software which works best for accounting, inventory management, supply chain management, retail, human resources, and more.\nTL;DR: FastAPI is better for high volume ‚Äî low latency, good integration choices; Frappe for low-code approach, tailored for ERP based use cases.\n\n\nPython ü§ù Gen A.I\nWith Python‚Äôs versatility and large network of libraries, it is the perfect choice for ML/AI based applications. With generative AI taking the internet by storm, it was no surprise to come across multiple talks, workshops and networking sessions that addressed the topic.\nOne such workshop gave great insight on building robust Retrieval Augmented Generation (RAG) systems. The current market for inference on documents with the help of LLMs is growing rapidly with multiple companies making use of these applications. The basics for building a good RAG system is quality extraction of data from documents, fine-tuning the hyper parameters, and using the right embeddings model.\nSome key questions for you to consider before building a RAG system include the type of task you want it to perform (summarization, document comparison, semantic search, recency filtering, masking PII information, etc.), what type of benchmarks you need it to pass, and how you are going to check for quality/accuracy of the response.\nIn most cases, we would have to make use of query routers, either to make two retrieval calls for document comparison, or routing the retrieval call between a SQL DB and a vector DB based on the nature of query and type of data to be retrieved (structured/unstructured). We can make use of frameworks such as LangChain or LLaMAIndex for developing quick PoCs. Check out this resource if you are unsure on which framework to use. If you want to know more about efficient scaling of these systems, check out this resource (Cross encoders, re-rankers, fast text search, improving reliability, etc).\nThe other major aspect which garnered considerable attention is that of cost and the future of generative AI. Various keynote speakers who work in the industry highlighted the pitfalls of currently available and mainstream LLMs ‚Äî sub optimally trained, blackbox nature, security concerns. People seemed to have a broad opinion that LLMs with 100B+ parameters would rarely be useful in real-world applications since the tasks are relatively well-defined and discrete (Example: Most companies don‚Äôt want their LLMs to write poems about John Cena and also be able to analyze their financial statements). The future of generative AI seems to be moving towards smaller parameter LLMs with a keen focus on high quality data and compute optimization to enable on-device capabilities for maximum outreach.\nTL;DR: Building and refining Retrieval Augmented Generation (RAG) systems; Future of gen AI ‚Äî smaller parameter LLMs with focus on high-quality data and compute optimization."
  },
  {
    "objectID": "posts/pycon_trip_report.html#summary",
    "href": "posts/pycon_trip_report.html#summary",
    "title": "Pycon India 2023 Trip Report",
    "section": "Summary",
    "text": "Summary\nOverall, the conference was an amazing experience which gave insights into various domains, what developers are working on, future of multiple technology related sectors, and the cool ways companies are solving pressing real-world problems.\nTo watch the recorded stream of keynotes click here.\nTo look at the talk proposals click here."
  },
  {
    "objectID": "posts/unveiling-power-and-privacy.html",
    "href": "posts/unveiling-power-and-privacy.html",
    "title": "Unveiling the Power and Privacy of Language Models in Fashion",
    "section": "",
    "text": "in the world of fashion"
  },
  {
    "objectID": "posts/unveiling-power-and-privacy.html#understanding-language-models",
    "href": "posts/unveiling-power-and-privacy.html#understanding-language-models",
    "title": "Unveiling the Power and Privacy of Language Models in Fashion",
    "section": "Understanding Language Models",
    "text": "Understanding Language Models\n Language models come in two flavours: LLMs and fine-tuned models. LLMs are big models trained on diverse data without specific adjustments for a particular task. On the other hand, fine-tuned models are smaller models tailored to a specific task. Fine-tuned models are like specialists, while LLMs are more like generalists. In the fashion world, the choice between LLMs and fine-tuned models depends on the specific requirements of the task at hand."
  },
  {
    "objectID": "posts/unveiling-power-and-privacy.html#practical-applications-in-fashion",
    "href": "posts/unveiling-power-and-privacy.html#practical-applications-in-fashion",
    "title": "Unveiling the Power and Privacy of Language Models in Fashion",
    "section": "Practical Applications in Fashion",
    "text": "Practical Applications in Fashion\n Language models have found their way into various fashion applications. They excel in natural language understanding, enabling them to comprehend fashion-related text and extract meaningful insights. Language models can also generate high-quality fashion content, such as writing articles, creating engaging social media posts, or assisting in chatbot interactions. Moreover, these models possess extensive knowledge about fashion trends and can assist in knowledge-intensive fashion tasks. Additionally, language models enhance reasoning abilities, helping in decision-making and problem-solving within the fashion industry."
  },
  {
    "objectID": "posts/unveiling-power-and-privacy.html#federated-learning-and-privacy",
    "href": "posts/unveiling-power-and-privacy.html#federated-learning-and-privacy",
    "title": "Unveiling the Power and Privacy of Language Models in Fashion",
    "section": "Federated Learning and Privacy",
    "text": "Federated Learning and Privacy\n To address privacy concerns, federated learning offers a distributed approach where models are trained locally and aggregated to create a global model. This method allows fashion companies to utilise data from multiple sources while preserving user privacy. Different approaches, such as centralised, decentralised, and heterogeneous federated learning, provide distinct benefits and challenges. By applying techniques like differential privacy, fashion industry researchers can strike a balance between utility and privacy, ensuring that language models preserve the confidentiality of sensitive fashion-related information."
  },
  {
    "objectID": "posts/unveiling-power-and-privacy.html#conclusion",
    "href": "posts/unveiling-power-and-privacy.html#conclusion",
    "title": "Unveiling the Power and Privacy of Language Models in Fashion",
    "section": "Conclusion",
    "text": "Conclusion\n Language models have become a game-changer in the fashion industry. Their ability to understand and generate human-like language opens up a world of possibilities for fashion-related tasks. With advancements in privacy techniques like differential privacy and federated learning, language models can protect the privacy of user data while providing accurate and valuable insights. As the fashion industry embraces these technologies, we can expect further advancements in fashion content creation, trend analysis, and personalised fashion recommendations."
  },
  {
    "objectID": "posts/you_dont_need_a_vector_database.html",
    "href": "posts/you_dont_need_a_vector_database.html",
    "title": "You (Probably) Don‚Äôt Need an Embedding Database",
    "section": "",
    "text": "Vector database on a set of digital scales\nIf you‚Äôve been paying attention to the recent advances in Large Language Models (LLM), you‚Äôve noticed that a whole new crop of startups emerged to provide search over embeddings.\nSearch over embeddings is a very different process than search over a database of documents. Embedding search uses a vector space representation of an image or document that has been created by a corresponding model, rather than an inverted index of terms and documents. Search in a vector space is typically handled with nearest neighbor search, which returns the embeddings of the closest records to the target record. This technique is much more intensive to calculate than a simple inverted index lookup, and accordingly databases need to make trade offs for precision/recall in order to provide reasonable performance over large sets of data."
  },
  {
    "objectID": "posts/you_dont_need_a_vector_database.html#embedding-databases-for-smaller-datasets",
    "href": "posts/you_dont_need_a_vector_database.html#embedding-databases-for-smaller-datasets",
    "title": "You (Probably) Don‚Äôt Need an Embedding Database",
    "section": "Embedding Databases for Smaller Datasets",
    "text": "Embedding Databases for Smaller Datasets\nHere at Hushh we were suprised to realize that there wasn‚Äôt a good option for smaller/portable embeddings for databases. Many modeling tasks rely on smaller and more domain-specific datasets to perform domain-specific tasks. For instance, image recognition models might need to index the products of a given storefront. There may be many thousand products, but often not the millions of products that would necessitate a standalone database. Furthermore, a standalone database would need to be running at all times, incurring a large one-time cost for any sort of embedding search functionality.\nIf one doesn‚Äôt have a lot of data, and doesn‚Äôt want to pay the maintenance fee on hosted embedding search, using an embedding search database is costly overkill, but what are the options?\nMany embedding databases and models use python, so accordingly, the embeddings can be exported in the python pickle format. However, the pickle format is unsafe, making it a risky bet for production systems.\nJSON formats can also be used for pickling data, but JSON requires all of the embedding data to be decoded and loaded into memory. This process can take a significant amount of time, making it costly to load/unload embedding datasets on the fly.\nMessagepack is another solid option, optimized for speed and portability. Originally, this was the format that we were likely to use. However, in the back of our minds we wondered, can we make it even faster?"
  },
  {
    "objectID": "posts/you_dont_need_a_vector_database.html#introducing-the-hushh-catalog-format",
    "href": "posts/you_dont_need_a_vector_database.html#introducing-the-hushh-catalog-format",
    "title": "You (Probably) Don‚Äôt Need an Embedding Database",
    "section": "Introducing The Hushh Catalog Format",
    "text": "Introducing The Hushh Catalog Format\nWe introduce the Hushh Catalog Format (HCF), a file format that is optimized for speedy (and lazy) loading of embeddings from disk.\nTo understand the performance benefits of the HCF format, we‚Äôll use this fashion dataset comprising ~44K product images, representative of the fashion offerings of a mid-to-large size department store.\nWe‚Äôll also take figures and data from this data science notebook that contains the result of the analysis."
  },
  {
    "objectID": "posts/you_dont_need_a_vector_database.html#comparisons",
    "href": "posts/you_dont_need_a_vector_database.html#comparisons",
    "title": "You (Probably) Don‚Äôt Need an Embedding Database",
    "section": "Comparisons",
    "text": "Comparisons\nFor the purposes of comparison, we‚Äôll generate embedding vectors in three different formats:\n\nJSON : A popular option for web development due to it being human-readable\nMsgpack : A schema-less binary format that is a good option for smaller/faster serialization\nHushh Catalog Format : A format with a schema designed especially for storing product information and metadata.\n\n\nFile Size\n\n\n\nFile Size Comparison\n\n\nFile sizes for smaller/embedded databases can add a lot of overhead for search. In our first comparison we look at the file size from our example dataset and see that HCF is half the size of messagepack, and a less than 25% the size of a comparable json format.\nFile size matters a lot for databases, particularly since files like messagepack and json need to be loaded fully into memory. If you have a bigger file format, your program will use more memory to store it internally, which adds overhead for resource usage and time.\n\n\n\nLoading Time Comparison\n\n\nInterestingly enough, the file size difference becomes even more pronounced when the loading time is compared. The HCF format is a whopping 20,000 times faster at loading the embedding data than JSON, and also beats msgpack by over an order of magnitude.\nHow is this possible?\nThe answer is that the Hushh Catalog Format reader doesn‚Äôt read in the data all at once. Instead, it streams it in as necessary directly from disk without needing to parse the entire file. This technique of lazy loading enables the Hushh Catalog Format to all but eliminate a startup delay when loading embedding data.\nWhat was used to build the Hushh Catalog Format?\nThe Hushh Catalog Format is built on top of flatbuffers. Flatbuffers is similar to protobuffers, except it‚Äôs designed for larger amounts of data that can be streamed lazily. Flatbuffers excel at loading densely packed numeric and textual data in a structured format. The structured format requires a schema, and here‚Äôs the current schema for Hushh Catalog Format\nUsing the schema, we can use flatbuffers to generate python runtime classes that stream the file into memory, along with some helper constructor methods. There‚Äôs runtime classes for Swift available as well, with more to come."
  },
  {
    "objectID": "posts/you_dont_need_a_vector_database.html#what-can-you-do-with-the-hushh-catalog-format",
    "href": "posts/you_dont_need_a_vector_database.html#what-can-you-do-with-the-hushh-catalog-format",
    "title": "You (Probably) Don‚Äôt Need an Embedding Database",
    "section": "What can you do with the Hushh Catalog Format?",
    "text": "What can you do with the Hushh Catalog Format?\nFor now, the format is geared towards providing catalog search services. Accordingly, information pertaining to products are supported. As we expand the scope of the format, we will enable more fine-tuned schemas for a growing number of open source personal data formats.\n\n\n\nVibe Search\n\n\nWe‚Äôre using the HCF format as a way of providing portable embedding indexes that are available from the phone or from a web server. Our Vibe search service will use it under the hood, making state of the art embedding search more easily available to everyone!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hushh Labs",
    "section": "",
    "text": "You (Probably) Don‚Äôt Need an Embedding Database\n\n\n\n\n\n\nembedding\n\n\nsearch\n\n\nopen source\n\n\n\nVector Databases are in vogue, but do you really need one to support your AI powered Search?\n\n\n\n\n\nJan 30, 2024\n\n\nJustin Donaldson\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Language Models and Related Data Privacy\n\n\n\n\n\n\nLLM\n\n\nPrivacy\n\n\n\nCustomers regularly express preferences for brands based on their attire. How can retail adapt and learn without compromising privacy?\n\n\n\n\n\nOct 19, 2023\n\n\nHarshvardhan, Justin Donaldson, Manish Sainani\n\n\n\n\n\n\n\n\n\n\n\n\nPycon India 2023 Trip Report\n\n\n\n\n\n\nconferences\n\n\ninsights\n\n\n\nA brief overview on the latest happenings within the global Python community\n\n\n\n\n\nSep 11, 2023\n\n\nDevesh Paragiri\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling the Power and Privacy of Language Models in Fashion\n\n\n\n\n\n\nLLM\n\n\nPrivacy\n\n\n\nIn the world of fashion, language models have become the talk of the town. These models, known as Large Language Models (LLMs), are making waves in the field of Natural Language Processing (NLP). With their ability to understand and generate human-like language, LLMs are revolutionising the way computers comprehend and communicate with us. They have practical applications in fashion-related tasks, such as understanding fashion trends, generating creative fashion content, and improving fashion recommendations.\n\n\n\n\n\nAug 27, 2023\n\n\nHarshvardhan\n\n\n\n\n\n\n\n\n\n\n\n\nHushh Manifesto\n\n\n\n\n\n\nmission\n\n\nprinciples\n\n\n\nWhat does Hushh believe? What are we working towards?\n\n\n\n\n\nJul 11, 2023\n\n\nManish Sainani, Justin Donaldson, Sunaz Sharaf\n\n\n\n\n\n\n\n\n\n\n\n\nLogo Analysis for Brand Affinity\n\n\n\n\n\n\nfashion\n\n\nML\n\n\nvision\n\n\n\nCustomers regularly express preferences for brands based on their attire. How can retail adapt and learn without compromising privacy?\n\n\n\n\n\nJul 11, 2023\n\n\nJustin Donaldson\n\n\n\n\n\n\n\n\n\n\n\n\nSearch and Discovery for Luxury Fashion\n\n\n\n\n\n\nsearch\n\n\nembedding\n\n\ndiscovery\n\n\n\nSearch and discovery go hand in hand when finding the frontiers for personal taste\n\n\n\n\n\nJul 10, 2023\n\n\nJustin Donaldson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html",
    "href": "posts/survey_on_llm_privacy.html",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "",
    "text": "AI Privacy"
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#pretraining-data",
    "href": "posts/survey_on_llm_privacy.html#pretraining-data",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Pretraining Data",
    "text": "Pretraining Data\nThis data plays a pivotal role as it forms the foundation for language models. Pretraining involves training language models on text sources such as websites and articles. This carefully curated data ensures that language models possess a rich understanding of word knowledge, grammar, syntax, semantics, context, and the ability to generate coherent responses. The diversity of pretraining data sets Large Language Models (LLMs) apart from other models in terms of usability."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#finetuning-data",
    "href": "posts/survey_on_llm_privacy.html#finetuning-data",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Finetuning Data",
    "text": "Finetuning Data\nThe choice between using LLMs or fine-tuned models depends on the availability of annotated data in three scenarios:\n\nZero Annotated Data\nWhen no annotated data is available, LLMs excel in a zero-shot setting. They outperform previous methods that do not rely on annotated data. LLMs avoid catastrophic forgetting, meaning their parameters remain unchanged as they don‚Äôt undergo a parameter update process.\n\n\nFew Annotated Data\nIf only a small amount of annotated data is available, LLMs incorporate these examples directly into their input prompt, known as in-context learning. This guides LLMs effectively and enables them to understand and perform tasks. Recent studies have shown that even with just one or a few annotated examples, LLMs can achieve significant improvements and match the performance of state-of-the-art fine-tuned models in open-domain tasks. Scaling LLMs can enhance their zero/few-shot capabilities. Fine-tuned models can also be improved using few-shot learning methods, but they may be outperformed by LLMs due to their smaller scale and potential overfitting.\n\n\nAbundant Annotated Data\nWhen a substantial amount of annotated data is available, both fine-tuned models and LLMs can be considered. Fine-tuned models fit the data well in most cases, but LLMs can be preferred when specific constraints like privacy need to be addressed. The choice between fine-tuned models and LLMs depends on factors like desired performance, computational resources, and deployment constraints specific to the task at hand."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#test-data",
    "href": "posts/survey_on_llm_privacy.html#test-data",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Test Data",
    "text": "Test Data\nThis refers to a set of examples used to evaluate the performance and accuracy of a model or system. It helps researchers and developers understand how well their models work and identify areas for improvement before real-world use. Test data is crucial as it reveals disparities between the trained data and new data, known as domain shifts. These shifts can hinder the performance of fine-tuned models due to their specific distribution and limited generalization ability.\nNow let‚Äôs delve into the utilization of LLMs (Large Language Models) and fine-tuned models in real-world tasks. In these scenarios, we often encounter a significant challenge called ‚ÄúNoisy data.‚Äù This means that the input received from real-world non-experts is not always clean and well-defined. These users may have limited knowledge of how to interact with the model or may not be fluent in using text. Another challenge is the lack of task formatting, where users may not clearly express their desired predictions or may have multiple implicit intents.\nTo overcome these challenges, it is crucial for models to understand user intents and provide outputs that align with those intents. However, real-world user requests often deviate significantly from the distribution of NLP datasets designed for specific tasks. Studies have shown that LLMs are better suited to handle real-world scenarios compared to fine-tuned models. This is because LLMs have been trained on diverse datasets that cover various writing styles, languages, and domains. They also demonstrate a strong ability to generate open-domain responses, making them well-suited for these real-world scenarios.\nOn the other hand, fine-tuned models are specifically tailored to well-defined tasks and may struggle to adapt to new or unexpected user requests. They rely heavily on clear objectives and well-formed training data that specify the types of instructions the models should learn to follow. These fine-tuned models may face challenges with noisy input due to their narrower focus on specific distributions and structured data.\nIn addition to considering real-world data, there are other factors that need to be taken into account, particularly the safety and privacy of user data. Since the present LLM giants are cloud-based, user data is communicated over the internet. This can pose serious security risks, especially when processing sensitive or confidential data with cloud giants. Therefore, before considering factors like cost, latency, robustness, or bias, it is essential to prioritize user privacy and ensure appropriate safeguards are in place."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#understanding-privacy",
    "href": "posts/survey_on_llm_privacy.html#understanding-privacy",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Understanding Privacy",
    "text": "Understanding Privacy\nBefore we delve into privacy concerns related to language models, let‚Äôs first understand what privacy means. According to Alan Estin, privacy is about individuals, groups, or institutions having control over how, when, and to what extent their information is shared with others. In the context of language models, there are significant digital privacy concerns."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#historical-privacy-measures",
    "href": "posts/survey_on_llm_privacy.html#historical-privacy-measures",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Historical Privacy Measures",
    "text": "Historical Privacy Measures\nIn the past, privacy concerns were addressed through techniques like anonymity and encryption. Anonymity involves keeping personal or identifiable information separate from data to ensure that individuals‚Äô identities are not linked to the data they generate. Encryption converts information into a coded form that can only be accessed by authorized parties. These measures aimed to protect privacy and limit access to user information."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#limitations-in-protecting-privacy",
    "href": "posts/survey_on_llm_privacy.html#limitations-in-protecting-privacy",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Limitations in Protecting Privacy",
    "text": "Limitations in Protecting Privacy\nHowever, these approaches are proving insufficient, especially when it comes to training machine learning models or language models. It is crucial that these models do not expose any private information from the training dataset. This has led to research on differential privacy algorithms."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#differential-privacy",
    "href": "posts/survey_on_llm_privacy.html#differential-privacy",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Differential Privacy",
    "text": "Differential Privacy\nDifferential privacy is a rigorous mathematical framework that can be applied to any algorithm. It has been successfully implemented by major companies in their data pipelines. In this section, we will explain the concept of differential privacy without delving into the mathematical details."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#privacy-attacks-and-privacy-loss",
    "href": "posts/survey_on_llm_privacy.html#privacy-attacks-and-privacy-loss",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Privacy Attacks and Privacy Loss",
    "text": "Privacy Attacks and Privacy Loss\nUnlike encryption or anonymization, differential privacy focuses on preventing privacy attacks. Privacy attacks occur when an entity or individual tries to gain access to private information by exploiting the behavior or output of a language model. Differential privacy addresses the concept of privacy leakage or privacy loss."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#key-concepts-in-differential-privacy",
    "href": "posts/survey_on_llm_privacy.html#key-concepts-in-differential-privacy",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Key Concepts in Differential Privacy",
    "text": "Key Concepts in Differential Privacy\n\nPrivacy Parameters: The level of privacy protection is controlled by a parameter called epsilon (\\(\\epsilon\\)). A smaller \\(\\epsilon\\) value provides stronger privacy guarantees.\nSensitivity: Sensitivity of a mechanism refers to how much the output can change when a single example is added or removed from the dataset. Sensitivity helps determine the amount of noise that needs to be added to achieve the desired privacy level.\nPrivacy Compromise: To address potential privacy compromises, (\\(\\epsilon, \\delta\\))-differential privacy is used, where \\(\\delta\\) represents the probability of privacy compromise."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#challenges-and-variations",
    "href": "posts/survey_on_llm_privacy.html#challenges-and-variations",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Challenges and Variations",
    "text": "Challenges and Variations\n\nPrivacy Loss Variance: Privacy loss variance means that different individuals may experience different levels of privacy loss.\nDifferential Privacy Extensions: In the field of research, there are more than 500 extensions of differential privacy available in literature, focusing on different scenarios, types of data, and attacker models.\nExternal Factors: In some cases, privacy can be compromised by external factors beyond the mechanism‚Äôs control.\nAlternative Approaches: There are alternative statistical approaches, like hypothesis testing, that can be used to interpret differential privacy."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#applying-differential-privacy-in-data-processing",
    "href": "posts/survey_on_llm_privacy.html#applying-differential-privacy-in-data-processing",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Applying Differential Privacy in Data Processing",
    "text": "Applying Differential Privacy in Data Processing\n\nData Preprocessing: Data preprocessing involves applying differential privacy to datasets before training the model, which helps protect sensitive information.\nOptimization Algorithm: Using differential privacy during the training process of the model‚Äôs parameters ensures privacy is maintained while learning from the data.\nLoss Function: Applying differential privacy to the result of the loss function just before updating the model‚Äôs parameters helps control privacy loss and maintain accuracy.\nFinal Trained Parameters: Differential privacy can also be applied to the final trained parameters of the model, ensuring privacy even when the model is in use."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#privacy-in-stochastic-gradient-descent",
    "href": "posts/survey_on_llm_privacy.html#privacy-in-stochastic-gradient-descent",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Privacy in Stochastic Gradient Descent",
    "text": "Privacy in Stochastic Gradient Descent\nIn deep learning, stochastic gradient descent (SGD) is used to train language models. It involves adding noise to the gradients during training to protect the privacy of the model parameters. This ensures that the model parameters do not reveal any private information."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#the-pate-algorithm",
    "href": "posts/survey_on_llm_privacy.html#the-pate-algorithm",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "The PATE Algorithm",
    "text": "The PATE Algorithm\nThe PATE algorithm takes a different approach to ensure privacy. It allows a public model to learn by combining the predictions of multiple models with added noise. This creates a public dataset with differentially private labels, which are used to train a differentially private model. This approach resembles synthetic data generation and provides a way to avoid leaking private data during data processing."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#local-differential-privacy-and-federated-learning",
    "href": "posts/survey_on_llm_privacy.html#local-differential-privacy-and-federated-learning",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Local Differential Privacy and Federated Learning",
    "text": "Local Differential Privacy and Federated Learning\nIn some cases, it may not be necessary to interact with a cloud server to work with a dataset. This is where ‚ÄúLocal‚Äù differential privacy can be useful. It provides a stronger privacy guarantee for individual users by using a version of the data that doesn‚Äôt store the original sensitive information. Federated Learning is introduced to handle the variability of different input data received by the server.\n\nCentralized Federated Learning\nCentralized Federated Learning involves a central server that coordinates the participating nodes to create a global model. Privacy is maintained by only sharing local models with a trusted aggregator.\n\n\nDecentralized Federated Learning\nDecentralized Federated Learning eliminates the central server, resulting in no single point of failure. However, it presents challenges in coordinating the learning process and network performance.\n\n\nHeterogeneous Federated Learning\nHeterogeneous Federated Learning allows for flexibility without making assumptions about data, devices, collaborative schemes, or models used. It requires careful optimization and coordination."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#challenges-and-improvements-in-large-language-models-llms",
    "href": "posts/survey_on_llm_privacy.html#challenges-and-improvements-in-large-language-models-llms",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Challenges and Improvements in Large Language Models (LLMs)",
    "text": "Challenges and Improvements in Large Language Models (LLMs)\nLarge language models (LLMs) have made remarkable strides in natural language processing, yet addressing various shortcomings is crucial for their further advancement and practical application. Future research should focus on the following areas:\n\nAddressing Bias and Fairness\n\nBias Mitigation: LLMs can perpetuate biases from training data, resulting in unfair and discriminatory outcomes. Future research should focus on developing debiasing techniques and meticulous dataset curation to ensure fairness.\n\n\n\nEnhancing Robustness\n\nHandling Noisy Data: LLMs often struggle with noisy or out-of-distribution data, leading to erroneous or nonsensical outputs. Enhancing their robustness is imperative to handle diverse scenarios encountered in real-world applications. Researchers should explore techniques that improve model generalization and adaptability.\n\n\n\nImproving Explainability\n\nEnhancing Interpretability: The lack of explainability and interpretability makes LLMs appear as black boxes, hindering the understanding of their reasoning behind predictions. To enhance trustworthiness, methods need to be developed to make LLMs more explainable, allowing users to comprehend the decision-making process.\n\n\n\nData Efficiency\n\nData-Efficient Models: LLMs typically rely on vast amounts of training data, which restricts their usability in domains with limited labeled data. It is crucial to investigate methods that improve data efficiency, enabling LLMs to perform well even with fewer training examples."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#potential-applications-of-llms",
    "href": "posts/survey_on_llm_privacy.html#potential-applications-of-llms",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Potential Applications of LLMs",
    "text": "Potential Applications of LLMs\nLLMs have a wide range of potential applications in various domains. They can be utilized in the following ways:\n\nCustomer Support and Chatbots\n\nCreating intelligent bots capable of accurately understanding and responding to user queries, thereby improving customer interactions.\n\n\n\nContent Generation\n\nAutomating content generation tasks, generating high-quality articles, blog posts, and product descriptions, benefiting content creators, marketers, and businesses.\n\n\n\nLanguage Translation\n\nEnhancing language translation systems, enabling more contextually accurate translations and breaking down language barriers.\n\n\n\nImproved Search Engines\n\nEnhancing the effectiveness of search engines by better comprehending user queries and offering more relevant search results, thereby enhancing the overall search experience.\n\nIt is crucial to carefully address factors like privacy, data protection, and ethical considerations when implementing LLMs in real-life applications, ensuring the development of valuable and user-friendly solutions."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#challenges-in-upscaling-data-for-llms",
    "href": "posts/survey_on_llm_privacy.html#challenges-in-upscaling-data-for-llms",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Challenges in Upscaling Data for LLMs",
    "text": "Challenges in Upscaling Data for LLMs\nUpscaling data for training Language Models (LLMs) presents various challenges. Researchers should explore techniques to address the following issues:\n\nComputational Resources\n\nHandling the significant computational resources encompassing storage and processing power required to upscale data for training LLMs.\n\n\n\nData Quality and Labeling\n\nEnsuring data quality and labeling becomes more complex when upscaling data, demanding meticulous quality control and annotation procedures to maintain accuracy and consistency.\n\n\n\nTraining Time\n\nProlonging the training time for LLMs when upscaling data, potentially impacting productivity and causing delays in research and development cycles.\n\n\n\nOverfitting\n\nThe risk of overfitting the model to the training data when upscaling, resulting in poor generalization to new and unseen examples.\n\nResearchers should explore techniques like distributed training, efficient data storage and processing frameworks, and automated quality assurance processes to ensure the scalability and reliability of upscaling data."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#failure-cases-in-differential-privacy",
    "href": "posts/survey_on_llm_privacy.html#failure-cases-in-differential-privacy",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Failure Cases in Differential Privacy",
    "text": "Failure Cases in Differential Privacy\nWhile differential privacy is a valuable technique for safeguarding individuals‚Äô data privacy, it may fall short in certain scenarios. Researchers should address the following failure cases:\n\nCorrelation Attacks\n\nWhen adversaries exploit correlations between multiple queries or released data points to unveil sensitive information, differential privacy mechanisms may not adequately protect against such attacks without accounting for correlations appropriately.\n\n\n\nAdversarial Use of Auxiliary Information\n\nAdversaries with access to auxiliary information can combine it with differentially private outputs to breach privacy, as differential privacy mechanisms do not safeguard against inferences made from external sources.\n\n\n\nInsider Attacks\n\nThe assumption of a trusted data curator in differential privacy leaves room for insider attacks, where privacy guarantees can be violated if the curator is malicious or colludes with attackers.\n\n\n\nRe-Identification Attacks\n\nAdversaries attempt to re-identify individuals in the dataset using background knowledge or external datasets, posing a threat to privacy. Differential privacy mechanisms may not provide sufficient protection against such attacks, especially when the dataset is sparse or contains unique identifiers.\n\nFuture research should prioritize the development of more robust differential privacy mechanisms, considering adversarial scenarios and exploring ways to incorporate additional privacy-preserving techniques."
  },
  {
    "objectID": "posts/survey_on_llm_privacy.html#open-ended-questions",
    "href": "posts/survey_on_llm_privacy.html#open-ended-questions",
    "title": "A Survey on Language Models and Related Data Privacy",
    "section": "Open-Ended Questions",
    "text": "Open-Ended Questions\nHere are some open-ended questions for the reader:\n\nHow can large language models be effectively utilized in domains with limited training data, considering the trade-off between model size and performance?\nWhat potential ethical implications arise from deploying large language models in real-world applications, and how can we ensure their responsible use?\nWhat measures should be taken to mitigate biases and ensure fairness in language models, considering their impact on decision-making processes?\nHow can we strike a balance between privacy and utility in language models, given the growing concerns about data protection and the need for accurate results?\nWhat potential risks and challenges are associated with upscaling data for training language models, and how can they be mitigated to ensure efficient and reliable model performance?"
  },
  {
    "objectID": "posts/manifesto.html",
    "href": "posts/manifesto.html",
    "title": "Hushh Manifesto",
    "section": "",
    "text": "Hushh Principles"
  },
  {
    "objectID": "posts/manifesto.html#access",
    "href": "posts/manifesto.html#access",
    "title": "Hushh Manifesto",
    "section": "Access:",
    "text": "Access:\nWe believe that access to information and resources should be inclusive, equitable, and easily attainable for everyone. Hushh aims to break down barriers and provide equal opportunities to all individuals, regardless of their background, location, or socio-economic status. Through our platform, we strive to create an ecosystem that fosters open communication, collaboration, and shared knowledge."
  },
  {
    "objectID": "posts/manifesto.html#control-choice",
    "href": "posts/manifesto.html#control-choice",
    "title": "Hushh Manifesto",
    "section": "Control (Choice):",
    "text": "Control (Choice):\nWe recognize that individuals should have complete control over their personal data and online presence. At Hushh, we prioritize privacy and provide users with the tools to make informed decisions about the information they share and how it is used. We respect the autonomy and agency of our users, empowering them to define their own digital experiences and safeguard their personal information."
  },
  {
    "objectID": "posts/manifesto.html#intelligence",
    "href": "posts/manifesto.html#intelligence",
    "title": "Hushh Manifesto",
    "section": "Intelligence :",
    "text": "Intelligence :\nWe believe that intelligence is the foundation of progress and growth. At Hushh, we leverage cutting-edge technologies, such as artificial intelligence and machine learning, to provide intelligent insights and personalized experiences. Our platform understands user preferences, adapts to their needs, and continuously learns to enhance the overall user experience. We harness the power of intelligence to empower individuals and help them make better decisions in their personal and professional lives."
  },
  {
    "objectID": "posts/manifesto.html#monetization-value-creation-for-the-user-of-the-platform",
    "href": "posts/manifesto.html#monetization-value-creation-for-the-user-of-the-platform",
    "title": "Hushh Manifesto",
    "section": "Monetization (Value Creation for the User of the Platform):",
    "text": "Monetization (Value Creation for the User of the Platform):\nWe understand the importance of value creation for our users. Hushh is committed to creating a sustainable ecosystem that enables individuals to monetize their skills, knowledge, and creations. We provide tools and opportunities for users to showcase their expertise, connect with like-minded individuals, and explore avenues for financial growth. Through our platform, users can unlock their full potential and realize the value they bring to the digital world.\nTogether, we envision a future where access is universal, control is in the hands of individuals, intelligence is seamlessly integrated, and monetization is fair and rewarding. At Hushh, we are dedicated to building a community-driven platform that challenges existing norms, fosters innovation, and empowers individuals to thrive in the digital age. Join us on this transformative journey as we shape a world where everyone‚Äôs voice is heard, respected, and valued. Together, we can build a future that embraces the true potential of technology and human ingenuity."
  },
  {
    "objectID": "posts/logo_analysis.html",
    "href": "posts/logo_analysis.html",
    "title": "Logo Analysis for Brand Affinity",
    "section": "",
    "text": "Logo Analysis\n\n\nIn today‚Äôs digital age, retailers are constantly seeking innovative ways to better understand their customers and build brand affinity. One powerful tool that is revolutionizing the retail industry is Hushh, a customer wallet platform that utilizes machine learning to analyze personal images and identify brand logos. By leveraging the power of computer vision and deep learning algorithms, Hushh provides retailers with valuable insights into customer preferences and behavior.\n\n\nHushh‚Äôs computer vision platform uses a combination of deep learning and computer vision techniques to identify logos in personal images. Whether it‚Äôs a logo on clothing, accessories, or products, Hushh can detect and analyze it. Once the logo is identified, the platform then determines the brand associated with it.\n\n\n\nOne of the key features of Hushh is its ability to track customer preferences over time. By analyzing personal images and customer sentiment, the platform provides retailers with valuable insights into how customer preferences evolve. This information is crucial for retailers to tailor their marketing strategies and offerings accordingly.\nBrands are a powerful way for users to express their personal preferences publicly. By capturing brand preference over time, retailers can gain a deeper and more immediate insight into what a customer is interested in when they arrive at the store.\nHushh is working on novel information displays to express customer brand preference. The following widget shows a force directed bubble plot of a customer‚Äôs favorite brands, sized according to how often that brand appears in their personal images. The widget below is fully interactive, enabling intuitive browsing of brands and brand categories.\n\n&lt;div id=\"quarto-navigation-envelope\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\"&gt;Hushh Labs&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\"&gt;Hushh Labs&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\"&gt;Home&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/index.html\"&gt;/index.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:About\"&gt;About&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/about.html\"&gt;/about.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/index.xml\"&gt;/index.xml&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"hidden\" data-render-id=\"margin-header\"&gt;\n&lt;div class=\"margin-header-item\"&gt;\n&lt;div id=\"mc_embed_shell\"&gt;\n      &lt;link href=\"//cdn-images.mailchimp.com/embedcode/classic-061523.css\" rel=\"stylesheet\" type=\"text/css\"&gt;\n  &lt;style type=\"text/css\"&gt;\n        #mc_embed_signup{background:#fff; false;clear:left; font:14px Helvetica,Arial,sans-serif; width: 240px;}\n        /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.\n           We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */\n&lt;/style&gt;\n&lt;div id=\"mc_embed_signup\"&gt;\n    &lt;form action=\"https://gitlab.us9.list-manage.com/subscribe/post?u=8054dab5be75ddd007416b5b9&amp;id=5647e13f15&amp;f_id=0066dfe0f0\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\"&gt;\n        &lt;div id=\"mc_embed_signup_scroll\"&gt;&lt;h2&gt;Subscribe to Hushh Labs&lt;/h2&gt;\n            &lt;div class=\"indicates-required\"&gt;&lt;span class=\"asterisk\"&gt;*&lt;/span&gt; indicates required&lt;/div&gt;\n            &lt;div class=\"mc-field-group\"&gt;&lt;label for=\"mce-FNAME\"&gt;First Name &lt;/label&gt;&lt;input type=\"text\" name=\"FNAME\" class=\" text\" id=\"mce-FNAME\" value=\"\"&gt;&lt;/div&gt;&lt;div class=\"mc-field-group\"&gt;&lt;label for=\"mce-EMAIL\"&gt;Email Address &lt;span class=\"asterisk\"&gt;*&lt;/span&gt;&lt;/label&gt;&lt;input type=\"email\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" required=\"\" value=\"\"&gt;&lt;/div&gt;\n        &lt;div id=\"mce-responses\" class=\"clear foot\"&gt;\n            &lt;div class=\"response\" id=\"mce-error-response\" style=\"display: none;\"&gt;&lt;/div&gt;\n            &lt;div class=\"response\" id=\"mce-success-response\" style=\"display: none;\"&gt;&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;div aria-hidden=\"true\" style=\"position: absolute; left: -5000px;\"&gt;\n        /* real people should not fill this in and expect good things - do not remove this or risk form bot signups */\n        &lt;input type=\"text\" name=\"b_8054dab5be75ddd007416b5b9_5647e13f15\" tabindex=\"-1\" value=\"\"&gt;\n    &lt;/div&gt;\n        &lt;div class=\"optionalParent\"&gt;\n            &lt;div class=\"clear foot\"&gt;\n                &lt;input type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\" value=\"Subscribe\"&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/form&gt;\n&lt;/div&gt;\n&lt;script type=\"text/javascript\" src=\"//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt;(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[1]=FNAME;ftypes[1]=merge;,fnames[0]=EMAIL;ftypes[0]=merge;,fnames[2]=LNAME;ftypes[2]=merge;,fnames[3]=ADDRESS;ftypes[3]=merge;,fnames[4]=PHONE;ftypes[4]=merge;,fnames[5]=BIRTHDAY;ftypes[5]=merge;false}(jQuery));var $mcj = jQuery.noConflict(true);&lt;/script&gt;&lt;/div&gt;\n\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-metatitle\"&gt;Hushh Labs - Logo Analysis for Brand Affinity&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\"&gt;Hushh Labs - Logo Analysis for Brand Affinity&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\"&gt;Hushh Labs - Logo Analysis for Brand Affinity&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-metasitename\"&gt;Hushh Labs&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercarddesc\"&gt;Customers regularly express preferences for brands based on their attire. How can retail adapt and learn without compromising privacy?&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardddesc\"&gt;Customers regularly express preferences for brands based on their attire. How can retail adapt and learn without compromising privacy?&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;/section&gt;\n\n&lt;/main&gt; &lt;!-- /main --&gt;\n&lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) {\n  const toggleBodyColorMode = (bsSheetEl) =&gt; {\n    const mode = bsSheetEl.getAttribute(\"data-mode\");\n    const bodyEl = window.document.querySelector(\"body\");\n    if (mode === \"dark\") {\n      bodyEl.classList.add(\"quarto-dark\");\n      bodyEl.classList.remove(\"quarto-light\");\n    } else {\n      bodyEl.classList.add(\"quarto-light\");\n      bodyEl.classList.remove(\"quarto-dark\");\n    }\n  }\n  const toggleBodyColorPrimary = () =&gt; {\n    const bsSheetEl = window.document.querySelector(\"link#quarto-bootstrap\");\n    if (bsSheetEl) {\n      toggleBodyColorMode(bsSheetEl);\n    }\n  }\n  toggleBodyColorPrimary();  \n  const icon = \"Óßã\";\n  const anchorJS = new window.AnchorJS();\n  anchorJS.options = {\n    placement: 'right',\n    icon: icon\n  };\n  anchorJS.add('.anchored');\n  const isCodeAnnotation = (el) =&gt; {\n    for (const clz of el.classList) {\n      if (clz.startsWith('code-annotation-')) {                     \n        return true;\n      }\n    }\n    return false;\n  }\n  const clipboard = new window.ClipboardJS('.code-copy-button', {\n    text: function(trigger) {\n      const codeEl = trigger.previousElementSibling.cloneNode(true);\n      for (const childEl of codeEl.children) {\n        if (isCodeAnnotation(childEl)) {\n          childEl.remove();\n        }\n      }\n      return codeEl.innerText;\n    }\n  });\n  clipboard.on('success', function(e) {\n    // button target\n    const button = e.trigger;\n    // don't keep focus\n    button.blur();\n    // flash \"checked\"\n    button.classList.add('code-copy-button-checked');\n    var currentTitle = button.getAttribute(\"title\");\n    button.setAttribute(\"title\", \"Copied!\");\n    let tooltip;\n    if (window.bootstrap) {\n      button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n      button.setAttribute(\"data-bs-placement\", \"left\");\n      button.setAttribute(\"data-bs-title\", \"Copied!\");\n      tooltip = new bootstrap.Tooltip(button, \n        { trigger: \"manual\", \n          customClass: \"code-copy-button-tooltip\",\n          offset: [0, -8]});\n      tooltip.show();    \n    }\n    setTimeout(function() {\n      if (tooltip) {\n        tooltip.hide();\n        button.removeAttribute(\"data-bs-title\");\n        button.removeAttribute(\"data-bs-toggle\");\n        button.removeAttribute(\"data-bs-placement\");\n      }\n      button.setAttribute(\"title\", currentTitle);\n      button.classList.remove('code-copy-button-checked');\n    }, 1000);\n    // clear code selection\n    e.clearSelection();\n  });\n  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {\n    const config = {\n      allowHTML: true,\n      maxWidth: 500,\n      delay: 100,\n      arrow: false,\n      appendTo: function(el) {\n          return el.parentElement;\n      },\n      interactive: true,\n      interactiveBorder: 10,\n      theme: 'quarto',\n      placement: 'bottom-start',\n    };\n    if (contentFn) {\n      config.content = contentFn;\n    }\n    if (onTriggerFn) {\n      config.onTrigger = onTriggerFn;\n    }\n    if (onUntriggerFn) {\n      config.onUntrigger = onUntriggerFn;\n    }\n    window.tippy(el, config); \n  }\n  const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n  for (var i=0; i&lt;noterefs.length; i++) {\n    const ref = noterefs[i];\n    tippyHover(ref, function() {\n      // use id or data attribute instead here\n      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n      try { href = new URL(href).hash; } catch {}\n      const id = href.replace(/^#\\/?/, \"\");\n      const note = window.document.getElementById(id);\n      return note.innerHTML;\n    });\n  }\n  const xrefs = window.document.querySelectorAll('a.quarto-xref');\n  const processXRef = (id, note) =&gt; {\n    // Strip column container classes\n    const stripColumnClz = (el) =&gt; {\n      el.classList.remove(\"page-full\", \"page-columns\");\n      if (el.children) {\n        for (const child of el.children) {\n          stripColumnClz(child);\n        }\n      }\n    }\n    stripColumnClz(note)\n    if (id === null || id.startsWith('sec-')) {\n      // Special case sections, only their first couple elements\n      const container = document.createElement(\"div\");\n      if (note.children && note.children.length &gt; 2) {\n        container.appendChild(note.children[0].cloneNode(true));\n        for (let i = 1; i &lt; note.children.length; i++) {\n          const child = note.children[i];\n          if (child.tagName === \"P\" && child.innerText === \"\") {\n            continue;\n          } else {\n            container.appendChild(child.cloneNode(true));\n            break;\n          }\n        }\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(container);\n        }\n        return container.innerHTML\n      } else {\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(note);\n        }\n        return note.innerHTML;\n      }\n    } else {\n      // Remove any anchor links if they are present\n      const anchorLink = note.querySelector('a.anchorjs-link');\n      if (anchorLink) {\n        anchorLink.remove();\n      }\n      if (window.Quarto?.typesetMath) {\n        window.Quarto.typesetMath(note);\n      }\n      // TODO in 1.5, we should make sure this works without a callout special case\n      if (note.classList.contains(\"callout\")) {\n        return note.outerHTML;\n      } else {\n        return note.innerHTML;\n      }\n    }\n  }\n  for (var i=0; i&lt;xrefs.length; i++) {\n    const xref = xrefs[i];\n    tippyHover(xref, undefined, function(instance) {\n      instance.disable();\n      let url = xref.getAttribute('href');\n      let hash = undefined; \n      if (url.startsWith('#')) {\n        hash = url;\n      } else {\n        try { hash = new URL(url).hash; } catch {}\n      }\n      if (hash) {\n        const id = hash.replace(/^#\\/?/, \"\");\n        const note = window.document.getElementById(id);\n        if (note !== null) {\n          try {\n            const html = processXRef(id, note.cloneNode(true));\n            instance.setContent(html);\n          } finally {\n            instance.enable();\n            instance.show();\n          }\n        } else {\n          // See if we can fetch this\n          fetch(url.split('#')[0])\n          .then(res =&gt; res.text())\n          .then(html =&gt; {\n            const parser = new DOMParser();\n            const htmlDoc = parser.parseFromString(html, \"text/html\");\n            const note = htmlDoc.getElementById(id);\n            if (note !== null) {\n              const html = processXRef(id, note);\n              instance.setContent(html);\n            } \n          }).finally(() =&gt; {\n            instance.enable();\n            instance.show();\n          });\n        }\n      } else {\n        // See if we can fetch a full url (with no hash to target)\n        // This is a special case and we should probably do some content thinning / targeting\n        fetch(url)\n        .then(res =&gt; res.text())\n        .then(html =&gt; {\n          const parser = new DOMParser();\n          const htmlDoc = parser.parseFromString(html, \"text/html\");\n          const note = htmlDoc.querySelector('main.content');\n          if (note !== null) {\n            // This should only happen for chapter cross references\n            // (since there is no id in the URL)\n            // remove the first header\n            if (note.children.length &gt; 0 && note.children[0].tagName === \"HEADER\") {\n              note.children[0].remove();\n            }\n            const html = processXRef(null, note);\n            instance.setContent(html);\n          } \n        }).finally(() =&gt; {\n          instance.enable();\n          instance.show();\n        });\n      }\n    }, function(instance) {\n    });\n  }\n      let selectedAnnoteEl;\n      const selectorForAnnotation = ( cell, annotation) =&gt; {\n        let cellAttr = 'data-code-cell=\"' + cell + '\"';\n        let lineAttr = 'data-code-annotation=\"' +  annotation + '\"';\n        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';\n        return selector;\n      }\n      const selectCodeLines = (annoteEl) =&gt; {\n        const doc = window.document;\n        const targetCell = annoteEl.getAttribute(\"data-target-cell\");\n        const targetAnnotation = annoteEl.getAttribute(\"data-target-annotation\");\n        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));\n        const lines = annoteSpan.getAttribute(\"data-code-lines\").split(\",\");\n        const lineIds = lines.map((line) =&gt; {\n          return targetCell + \"-\" + line;\n        })\n        let top = null;\n        let height = null;\n        let parent = null;\n        if (lineIds.length &gt; 0) {\n            //compute the position of the single el (top and bottom and make a div)\n            const el = window.document.getElementById(lineIds[0]);\n            top = el.offsetTop;\n            height = el.offsetHeight;\n            parent = el.parentElement.parentElement;\n          if (lineIds.length &gt; 1) {\n            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);\n            const bottom = lastEl.offsetTop + lastEl.offsetHeight;\n            height = bottom - top;\n          }\n          if (top !== null && height !== null && parent !== null) {\n            // cook up a div (if necessary) and position it \n            let div = window.document.getElementById(\"code-annotation-line-highlight\");\n            if (div === null) {\n              div = window.document.createElement(\"div\");\n              div.setAttribute(\"id\", \"code-annotation-line-highlight\");\n              div.style.position = 'absolute';\n              parent.appendChild(div);\n            }\n            div.style.top = top - 2 + \"px\";\n            div.style.height = height + 4 + \"px\";\n            div.style.left = 0;\n            let gutterDiv = window.document.getElementById(\"code-annotation-line-highlight-gutter\");\n            if (gutterDiv === null) {\n              gutterDiv = window.document.createElement(\"div\");\n              gutterDiv.setAttribute(\"id\", \"code-annotation-line-highlight-gutter\");\n              gutterDiv.style.position = 'absolute';\n              const codeCell = window.document.getElementById(targetCell);\n              const gutter = codeCell.querySelector('.code-annotation-gutter');\n              gutter.appendChild(gutterDiv);\n            }\n            gutterDiv.style.top = top - 2 + \"px\";\n            gutterDiv.style.height = height + 4 + \"px\";\n          }\n          selectedAnnoteEl = annoteEl;\n        }\n      };\n      const unselectCodeLines = () =&gt; {\n        const elementsIds = [\"code-annotation-line-highlight\", \"code-annotation-line-highlight-gutter\"];\n        elementsIds.forEach((elId) =&gt; {\n          const div = window.document.getElementById(elId);\n          if (div) {\n            div.remove();\n          }\n        });\n        selectedAnnoteEl = undefined;\n      };\n        // Handle positioning of the toggle\n    window.addEventListener(\n      \"resize\",\n      throttle(() =&gt; {\n        elRect = undefined;\n        if (selectedAnnoteEl) {\n          selectCodeLines(selectedAnnoteEl);\n        }\n      }, 10)\n    );\n    function throttle(fn, ms) {\n    let throttle = false;\n    let timer;\n      return (...args) =&gt; {\n        if(!throttle) { // first call gets through\n            fn.apply(this, args);\n            throttle = true;\n        } else { // all the others get throttled\n            if(timer) clearTimeout(timer); // cancel #2\n            timer = setTimeout(() =&gt; {\n              fn.apply(this, args);\n              timer = throttle = false;\n            }, ms);\n        }\n      };\n    }\n      // Attach click handler to the DT\n      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');\n      for (const annoteDlNode of annoteDls) {\n        annoteDlNode.addEventListener('click', (event) =&gt; {\n          const clickedEl = event.target;\n          if (clickedEl !== selectedAnnoteEl) {\n            unselectCodeLines();\n            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');\n            if (activeEl) {\n              activeEl.classList.remove('code-annotation-active');\n            }\n            selectCodeLines(clickedEl);\n            clickedEl.classList.add('code-annotation-active');\n          } else {\n            // Unselect the line\n            unselectCodeLines();\n            clickedEl.classList.remove('code-annotation-active');\n          }\n        });\n      }\n  const findCites = (el) =&gt; {\n    const parentEl = el.parentElement;\n    if (parentEl) {\n      const cites = parentEl.dataset.cites;\n      if (cites) {\n        return {\n          el,\n          cites: cites.split(' ')\n        };\n      } else {\n        return findCites(el.parentElement)\n      }\n    } else {\n      return undefined;\n    }\n  };\n  var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n  for (var i=0; i&lt;bibliorefs.length; i++) {\n    const ref = bibliorefs[i];\n    const citeInfo = findCites(ref);\n    if (citeInfo) {\n      tippyHover(citeInfo.el, function() {\n        var popup = window.document.createElement('div');\n        citeInfo.cites.forEach(function(cite) {\n          var citeDiv = window.document.createElement('div');\n          citeDiv.classList.add('hanging-indent');\n          citeDiv.classList.add('csl-entry');\n          var biblioDiv = window.document.getElementById('ref-' + cite);\n          if (biblioDiv) {\n            citeDiv.innerHTML = biblioDiv.innerHTML;\n          }\n          popup.appendChild(citeDiv);\n        });\n        return popup.innerHTML;\n      });\n    }\n  }\n});\n&lt;/script&gt;\n&lt;/div&gt; &lt;!-- /content --&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "posts/logo_analysis.html#how-does-hushh-logo-analysis-work",
    "href": "posts/logo_analysis.html#how-does-hushh-logo-analysis-work",
    "title": "Logo Analysis for Brand Affinity",
    "section": "",
    "text": "Hushh‚Äôs computer vision platform uses a combination of deep learning and computer vision techniques to identify logos in personal images. Whether it‚Äôs a logo on clothing, accessories, or products, Hushh can detect and analyze it. Once the logo is identified, the platform then determines the brand associated with it."
  },
  {
    "objectID": "posts/logo_analysis.html#capturing-brand-preference-over-time",
    "href": "posts/logo_analysis.html#capturing-brand-preference-over-time",
    "title": "Logo Analysis for Brand Affinity",
    "section": "",
    "text": "One of the key features of Hushh is its ability to track customer preferences over time. By analyzing personal images and customer sentiment, the platform provides retailers with valuable insights into how customer preferences evolve. This information is crucial for retailers to tailor their marketing strategies and offerings accordingly.\nBrands are a powerful way for users to express their personal preferences publicly. By capturing brand preference over time, retailers can gain a deeper and more immediate insight into what a customer is interested in when they arrive at the store.\nHushh is working on novel information displays to express customer brand preference. The following widget shows a force directed bubble plot of a customer‚Äôs favorite brands, sized according to how often that brand appears in their personal images. The widget below is fully interactive, enabling intuitive browsing of brands and brand categories.\n\n&lt;div id=\"quarto-navigation-envelope\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\"&gt;Hushh Labs&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\"&gt;Hushh Labs&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\"&gt;Home&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/index.html\"&gt;/index.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:About\"&gt;About&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/about.html\"&gt;/about.html&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-int-navbar:/index.xml\"&gt;/index.xml&lt;/span&gt;&lt;/p&gt;\n&lt;div class=\"hidden\" data-render-id=\"margin-header\"&gt;\n&lt;div class=\"margin-header-item\"&gt;\n&lt;div id=\"mc_embed_shell\"&gt;\n      &lt;link href=\"//cdn-images.mailchimp.com/embedcode/classic-061523.css\" rel=\"stylesheet\" type=\"text/css\"&gt;\n  &lt;style type=\"text/css\"&gt;\n        #mc_embed_signup{background:#fff; false;clear:left; font:14px Helvetica,Arial,sans-serif; width: 240px;}\n        /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.\n           We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */\n&lt;/style&gt;\n&lt;div id=\"mc_embed_signup\"&gt;\n    &lt;form action=\"https://gitlab.us9.list-manage.com/subscribe/post?u=8054dab5be75ddd007416b5b9&amp;id=5647e13f15&amp;f_id=0066dfe0f0\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\"&gt;\n        &lt;div id=\"mc_embed_signup_scroll\"&gt;&lt;h2&gt;Subscribe to Hushh Labs&lt;/h2&gt;\n            &lt;div class=\"indicates-required\"&gt;&lt;span class=\"asterisk\"&gt;*&lt;/span&gt; indicates required&lt;/div&gt;\n            &lt;div class=\"mc-field-group\"&gt;&lt;label for=\"mce-FNAME\"&gt;First Name &lt;/label&gt;&lt;input type=\"text\" name=\"FNAME\" class=\" text\" id=\"mce-FNAME\" value=\"\"&gt;&lt;/div&gt;&lt;div class=\"mc-field-group\"&gt;&lt;label for=\"mce-EMAIL\"&gt;Email Address &lt;span class=\"asterisk\"&gt;*&lt;/span&gt;&lt;/label&gt;&lt;input type=\"email\" name=\"EMAIL\" class=\"required email\" id=\"mce-EMAIL\" required=\"\" value=\"\"&gt;&lt;/div&gt;\n        &lt;div id=\"mce-responses\" class=\"clear foot\"&gt;\n            &lt;div class=\"response\" id=\"mce-error-response\" style=\"display: none;\"&gt;&lt;/div&gt;\n            &lt;div class=\"response\" id=\"mce-success-response\" style=\"display: none;\"&gt;&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;div aria-hidden=\"true\" style=\"position: absolute; left: -5000px;\"&gt;\n        /* real people should not fill this in and expect good things - do not remove this or risk form bot signups */\n        &lt;input type=\"text\" name=\"b_8054dab5be75ddd007416b5b9_5647e13f15\" tabindex=\"-1\" value=\"\"&gt;\n    &lt;/div&gt;\n        &lt;div class=\"optionalParent\"&gt;\n            &lt;div class=\"clear foot\"&gt;\n                &lt;input type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\" value=\"Subscribe\"&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/form&gt;\n&lt;/div&gt;\n&lt;script type=\"text/javascript\" src=\"//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt;(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[1]=FNAME;ftypes[1]=merge;,fnames[0]=EMAIL;ftypes[0]=merge;,fnames[2]=LNAME;ftypes[2]=merge;,fnames[3]=ADDRESS;ftypes[3]=merge;,fnames[4]=PHONE;ftypes[4]=merge;,fnames[5]=BIRTHDAY;ftypes[5]=merge;false}(jQuery));var $mcj = jQuery.noConflict(true);&lt;/script&gt;&lt;/div&gt;\n\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-metatitle\"&gt;Hushh Labs - Logo Analysis for Brand Affinity&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\"&gt;Hushh Labs - Logo Analysis for Brand Affinity&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\"&gt;Hushh Labs - Logo Analysis for Brand Affinity&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-metasitename\"&gt;Hushh Labs&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercarddesc\"&gt;Customers regularly express preferences for brands based on their attire. How can retail adapt and learn without compromising privacy?&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardddesc\"&gt;Customers regularly express preferences for brands based on their attire. How can retail adapt and learn without compromising privacy?&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;/section&gt;\n\n&lt;/main&gt; &lt;!-- /main --&gt;\n&lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) {\n  const toggleBodyColorMode = (bsSheetEl) =&gt; {\n    const mode = bsSheetEl.getAttribute(\"data-mode\");\n    const bodyEl = window.document.querySelector(\"body\");\n    if (mode === \"dark\") {\n      bodyEl.classList.add(\"quarto-dark\");\n      bodyEl.classList.remove(\"quarto-light\");\n    } else {\n      bodyEl.classList.add(\"quarto-light\");\n      bodyEl.classList.remove(\"quarto-dark\");\n    }\n  }\n  const toggleBodyColorPrimary = () =&gt; {\n    const bsSheetEl = window.document.querySelector(\"link#quarto-bootstrap\");\n    if (bsSheetEl) {\n      toggleBodyColorMode(bsSheetEl);\n    }\n  }\n  toggleBodyColorPrimary();  \n  const icon = \"Óßã\";\n  const anchorJS = new window.AnchorJS();\n  anchorJS.options = {\n    placement: 'right',\n    icon: icon\n  };\n  anchorJS.add('.anchored');\n  const isCodeAnnotation = (el) =&gt; {\n    for (const clz of el.classList) {\n      if (clz.startsWith('code-annotation-')) {                     \n        return true;\n      }\n    }\n    return false;\n  }\n  const clipboard = new window.ClipboardJS('.code-copy-button', {\n    text: function(trigger) {\n      const codeEl = trigger.previousElementSibling.cloneNode(true);\n      for (const childEl of codeEl.children) {\n        if (isCodeAnnotation(childEl)) {\n          childEl.remove();\n        }\n      }\n      return codeEl.innerText;\n    }\n  });\n  clipboard.on('success', function(e) {\n    // button target\n    const button = e.trigger;\n    // don't keep focus\n    button.blur();\n    // flash \"checked\"\n    button.classList.add('code-copy-button-checked');\n    var currentTitle = button.getAttribute(\"title\");\n    button.setAttribute(\"title\", \"Copied!\");\n    let tooltip;\n    if (window.bootstrap) {\n      button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n      button.setAttribute(\"data-bs-placement\", \"left\");\n      button.setAttribute(\"data-bs-title\", \"Copied!\");\n      tooltip = new bootstrap.Tooltip(button, \n        { trigger: \"manual\", \n          customClass: \"code-copy-button-tooltip\",\n          offset: [0, -8]});\n      tooltip.show();    \n    }\n    setTimeout(function() {\n      if (tooltip) {\n        tooltip.hide();\n        button.removeAttribute(\"data-bs-title\");\n        button.removeAttribute(\"data-bs-toggle\");\n        button.removeAttribute(\"data-bs-placement\");\n      }\n      button.setAttribute(\"title\", currentTitle);\n      button.classList.remove('code-copy-button-checked');\n    }, 1000);\n    // clear code selection\n    e.clearSelection();\n  });\n  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {\n    const config = {\n      allowHTML: true,\n      maxWidth: 500,\n      delay: 100,\n      arrow: false,\n      appendTo: function(el) {\n          return el.parentElement;\n      },\n      interactive: true,\n      interactiveBorder: 10,\n      theme: 'quarto',\n      placement: 'bottom-start',\n    };\n    if (contentFn) {\n      config.content = contentFn;\n    }\n    if (onTriggerFn) {\n      config.onTrigger = onTriggerFn;\n    }\n    if (onUntriggerFn) {\n      config.onUntrigger = onUntriggerFn;\n    }\n    window.tippy(el, config); \n  }\n  const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n  for (var i=0; i&lt;noterefs.length; i++) {\n    const ref = noterefs[i];\n    tippyHover(ref, function() {\n      // use id or data attribute instead here\n      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n      try { href = new URL(href).hash; } catch {}\n      const id = href.replace(/^#\\/?/, \"\");\n      const note = window.document.getElementById(id);\n      return note.innerHTML;\n    });\n  }\n  const xrefs = window.document.querySelectorAll('a.quarto-xref');\n  const processXRef = (id, note) =&gt; {\n    // Strip column container classes\n    const stripColumnClz = (el) =&gt; {\n      el.classList.remove(\"page-full\", \"page-columns\");\n      if (el.children) {\n        for (const child of el.children) {\n          stripColumnClz(child);\n        }\n      }\n    }\n    stripColumnClz(note)\n    if (id === null || id.startsWith('sec-')) {\n      // Special case sections, only their first couple elements\n      const container = document.createElement(\"div\");\n      if (note.children && note.children.length &gt; 2) {\n        container.appendChild(note.children[0].cloneNode(true));\n        for (let i = 1; i &lt; note.children.length; i++) {\n          const child = note.children[i];\n          if (child.tagName === \"P\" && child.innerText === \"\") {\n            continue;\n          } else {\n            container.appendChild(child.cloneNode(true));\n            break;\n          }\n        }\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(container);\n        }\n        return container.innerHTML\n      } else {\n        if (window.Quarto?.typesetMath) {\n          window.Quarto.typesetMath(note);\n        }\n        return note.innerHTML;\n      }\n    } else {\n      // Remove any anchor links if they are present\n      const anchorLink = note.querySelector('a.anchorjs-link');\n      if (anchorLink) {\n        anchorLink.remove();\n      }\n      if (window.Quarto?.typesetMath) {\n        window.Quarto.typesetMath(note);\n      }\n      // TODO in 1.5, we should make sure this works without a callout special case\n      if (note.classList.contains(\"callout\")) {\n        return note.outerHTML;\n      } else {\n        return note.innerHTML;\n      }\n    }\n  }\n  for (var i=0; i&lt;xrefs.length; i++) {\n    const xref = xrefs[i];\n    tippyHover(xref, undefined, function(instance) {\n      instance.disable();\n      let url = xref.getAttribute('href');\n      let hash = undefined; \n      if (url.startsWith('#')) {\n        hash = url;\n      } else {\n        try { hash = new URL(url).hash; } catch {}\n      }\n      if (hash) {\n        const id = hash.replace(/^#\\/?/, \"\");\n        const note = window.document.getElementById(id);\n        if (note !== null) {\n          try {\n            const html = processXRef(id, note.cloneNode(true));\n            instance.setContent(html);\n          } finally {\n            instance.enable();\n            instance.show();\n          }\n        } else {\n          // See if we can fetch this\n          fetch(url.split('#')[0])\n          .then(res =&gt; res.text())\n          .then(html =&gt; {\n            const parser = new DOMParser();\n            const htmlDoc = parser.parseFromString(html, \"text/html\");\n            const note = htmlDoc.getElementById(id);\n            if (note !== null) {\n              const html = processXRef(id, note);\n              instance.setContent(html);\n            } \n          }).finally(() =&gt; {\n            instance.enable();\n            instance.show();\n          });\n        }\n      } else {\n        // See if we can fetch a full url (with no hash to target)\n        // This is a special case and we should probably do some content thinning / targeting\n        fetch(url)\n        .then(res =&gt; res.text())\n        .then(html =&gt; {\n          const parser = new DOMParser();\n          const htmlDoc = parser.parseFromString(html, \"text/html\");\n          const note = htmlDoc.querySelector('main.content');\n          if (note !== null) {\n            // This should only happen for chapter cross references\n            // (since there is no id in the URL)\n            // remove the first header\n            if (note.children.length &gt; 0 && note.children[0].tagName === \"HEADER\") {\n              note.children[0].remove();\n            }\n            const html = processXRef(null, note);\n            instance.setContent(html);\n          } \n        }).finally(() =&gt; {\n          instance.enable();\n          instance.show();\n        });\n      }\n    }, function(instance) {\n    });\n  }\n      let selectedAnnoteEl;\n      const selectorForAnnotation = ( cell, annotation) =&gt; {\n        let cellAttr = 'data-code-cell=\"' + cell + '\"';\n        let lineAttr = 'data-code-annotation=\"' +  annotation + '\"';\n        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';\n        return selector;\n      }\n      const selectCodeLines = (annoteEl) =&gt; {\n        const doc = window.document;\n        const targetCell = annoteEl.getAttribute(\"data-target-cell\");\n        const targetAnnotation = annoteEl.getAttribute(\"data-target-annotation\");\n        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));\n        const lines = annoteSpan.getAttribute(\"data-code-lines\").split(\",\");\n        const lineIds = lines.map((line) =&gt; {\n          return targetCell + \"-\" + line;\n        })\n        let top = null;\n        let height = null;\n        let parent = null;\n        if (lineIds.length &gt; 0) {\n            //compute the position of the single el (top and bottom and make a div)\n            const el = window.document.getElementById(lineIds[0]);\n            top = el.offsetTop;\n            height = el.offsetHeight;\n            parent = el.parentElement.parentElement;\n          if (lineIds.length &gt; 1) {\n            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);\n            const bottom = lastEl.offsetTop + lastEl.offsetHeight;\n            height = bottom - top;\n          }\n          if (top !== null && height !== null && parent !== null) {\n            // cook up a div (if necessary) and position it \n            let div = window.document.getElementById(\"code-annotation-line-highlight\");\n            if (div === null) {\n              div = window.document.createElement(\"div\");\n              div.setAttribute(\"id\", \"code-annotation-line-highlight\");\n              div.style.position = 'absolute';\n              parent.appendChild(div);\n            }\n            div.style.top = top - 2 + \"px\";\n            div.style.height = height + 4 + \"px\";\n            div.style.left = 0;\n            let gutterDiv = window.document.getElementById(\"code-annotation-line-highlight-gutter\");\n            if (gutterDiv === null) {\n              gutterDiv = window.document.createElement(\"div\");\n              gutterDiv.setAttribute(\"id\", \"code-annotation-line-highlight-gutter\");\n              gutterDiv.style.position = 'absolute';\n              const codeCell = window.document.getElementById(targetCell);\n              const gutter = codeCell.querySelector('.code-annotation-gutter');\n              gutter.appendChild(gutterDiv);\n            }\n            gutterDiv.style.top = top - 2 + \"px\";\n            gutterDiv.style.height = height + 4 + \"px\";\n          }\n          selectedAnnoteEl = annoteEl;\n        }\n      };\n      const unselectCodeLines = () =&gt; {\n        const elementsIds = [\"code-annotation-line-highlight\", \"code-annotation-line-highlight-gutter\"];\n        elementsIds.forEach((elId) =&gt; {\n          const div = window.document.getElementById(elId);\n          if (div) {\n            div.remove();\n          }\n        });\n        selectedAnnoteEl = undefined;\n      };\n        // Handle positioning of the toggle\n    window.addEventListener(\n      \"resize\",\n      throttle(() =&gt; {\n        elRect = undefined;\n        if (selectedAnnoteEl) {\n          selectCodeLines(selectedAnnoteEl);\n        }\n      }, 10)\n    );\n    function throttle(fn, ms) {\n    let throttle = false;\n    let timer;\n      return (...args) =&gt; {\n        if(!throttle) { // first call gets through\n            fn.apply(this, args);\n            throttle = true;\n        } else { // all the others get throttled\n            if(timer) clearTimeout(timer); // cancel #2\n            timer = setTimeout(() =&gt; {\n              fn.apply(this, args);\n              timer = throttle = false;\n            }, ms);\n        }\n      };\n    }\n      // Attach click handler to the DT\n      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');\n      for (const annoteDlNode of annoteDls) {\n        annoteDlNode.addEventListener('click', (event) =&gt; {\n          const clickedEl = event.target;\n          if (clickedEl !== selectedAnnoteEl) {\n            unselectCodeLines();\n            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');\n            if (activeEl) {\n              activeEl.classList.remove('code-annotation-active');\n            }\n            selectCodeLines(clickedEl);\n            clickedEl.classList.add('code-annotation-active');\n          } else {\n            // Unselect the line\n            unselectCodeLines();\n            clickedEl.classList.remove('code-annotation-active');\n          }\n        });\n      }\n  const findCites = (el) =&gt; {\n    const parentEl = el.parentElement;\n    if (parentEl) {\n      const cites = parentEl.dataset.cites;\n      if (cites) {\n        return {\n          el,\n          cites: cites.split(' ')\n        };\n      } else {\n        return findCites(el.parentElement)\n      }\n    } else {\n      return undefined;\n    }\n  };\n  var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n  for (var i=0; i&lt;bibliorefs.length; i++) {\n    const ref = bibliorefs[i];\n    const citeInfo = findCites(ref);\n    if (citeInfo) {\n      tippyHover(citeInfo.el, function() {\n        var popup = window.document.createElement('div');\n        citeInfo.cites.forEach(function(cite) {\n          var citeDiv = window.document.createElement('div');\n          citeDiv.classList.add('hanging-indent');\n          citeDiv.classList.add('csl-entry');\n          var biblioDiv = window.document.getElementById('ref-' + cite);\n          if (biblioDiv) {\n            citeDiv.innerHTML = biblioDiv.innerHTML;\n          }\n          popup.appendChild(citeDiv);\n        });\n        return popup.innerHTML;\n      });\n    }\n  }\n});\n&lt;/script&gt;\n&lt;/div&gt; &lt;!-- /content --&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "posts/image_search_with_text.html",
    "href": "posts/image_search_with_text.html",
    "title": "Search and Discovery for Luxury Fashion",
    "section": "",
    "text": "Enhancing the search for the expression of self"
  },
  {
    "objectID": "posts/image_search_with_text.html#unleashing-the-potential-of-llm-embeddings",
    "href": "posts/image_search_with_text.html#unleashing-the-potential-of-llm-embeddings",
    "title": "Search and Discovery for Luxury Fashion",
    "section": "Unleashing the Potential of LLM Embeddings",
    "text": "Unleashing the Potential of LLM Embeddings\nLarge Language Models, such as GPT-3.5, possess remarkable natural language processing capabilities. Trained on massive amounts of textual data, these models acquire a deep understanding of language nuances, syntax, and semantics in a broad array of cultural contexts. LLM embeddings are numerical representations derived from text, capturing the intricate contextual information inherent in sentences, paragraphs, or documents."
  },
  {
    "objectID": "posts/image_search_with_text.html#why-embedding-search-for-stylistic-search",
    "href": "posts/image_search_with_text.html#why-embedding-search-for-stylistic-search",
    "title": "Search and Discovery for Luxury Fashion",
    "section": "Why Embedding Search for Stylistic Search?",
    "text": "Why Embedding Search for Stylistic Search?\nBy harnessing the power of LLM embeddings, we unlock a number of advantages for searching or navigating a particular style:\n\nEnhanced Semantic Relevance\n\nLLM embeddings encapsulate a profound comprehension of language semantics, leading to remarkably accurate search results. In the context of luxury fashion, where precision and exquisite details matter, LLM embeddings grasp the subtle nuances and connotations associated with the imagery high-end fashion. This visio-semantic awareness ensures that search results align with the desired level of opulence, refinement, and aesthetic appeal.\nFor instance, LLM embedding search can identify items not only by color, but also by abstract concepts of style, such as ‚Äúdress shoes‚Äù.\n\n\n\nImage of dress shoes\n\n\nKeep in mind that this particular search engine does not include any terminology related to shoes or style. The query process is entirely driven from image analysis alone.\n\nFashion-Specific Vocabulary and Concepts\n\nLuxury fashion is an industry replete with distinct terminologies and industry-specific jargon. Traditional TF/IDF search may struggle to capture the essence of these nuanced fashion terms, leading to suboptimal search outcomes. Conversely, LLM embeddings excel in comprehending fashion-specific vocabulary, recognizing brand names, fashion trends, and intricate design elements. This prowess enables users to delve into the world of luxury fashion with unparalleled accuracy.\n\n\n\nImage of wedge heel\n\n\n\nContext-Aware Search\n\nIn the realm of luxury fashion, context plays a pivotal role in understanding the true essence of a product. LLM embeddings excel at capturing the contextual information present in the shape of a product, leading to more refined and contextually appropriate image search results. Users can now effortlessly explore images that encapsulate the desired style, occasion, or fashion statement, ensuring a seamless and personalized luxury fashion journey.\n\n\n\nImage of vacation shoes\n\n\n\nUniting Text and Visuals\n\nThe marriage of text and visuals is at the heart of luxury fashion image search. LLM embeddings act as a bridge, facilitating a seamless connection between the textual descriptions and the visual representation of fashion products. By leveraging LLM embeddings, users can effortlessly navigate the realm of luxury fashion, exploring visually captivating images that align with their refined tastes and preferences.\nIn conclusion, the use of LLM embeddings for luxury fashion image search transcends the limitations of conventional TF/IDF search. By harnessing the semantic understanding, fashion-specific vocabulary, and contextual awareness ingrained in LLM embeddings, users can embark on a visually enchanting journey through the world of luxury fashion. Experience the epitome of elegance and style like never before, with LLM-powered image search in luxury fashion."
  }
]